{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the libraries that are needed\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid pdf header: b'PK\\x03\\x04\\x14'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EOF marker not found\n"
     ]
    },
    {
     "ename": "PdfStreamError",
     "evalue": "Stream has ended unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPdfStreamError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/mnt/process_pdf_text.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://domino-glue01.pg.wwtatc.ai/mnt/process_pdf_text.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m loader \u001b[39m=\u001b[39m PyPDFLoader(files[\u001b[39m0\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell://domino-glue01.pg.wwtatc.ai/mnt/process_pdf_text.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m text_splitter \u001b[39m=\u001b[39m RecursiveCharacterTextSplitter(\n\u001b[1;32m      <a href='vscode-notebook-cell://domino-glue01.pg.wwtatc.ai/mnt/process_pdf_text.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     chunk_size \u001b[39m=\u001b[39m \u001b[39m5000\u001b[39m,  \u001b[39m# size of each chunk created\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://domino-glue01.pg.wwtatc.ai/mnt/process_pdf_text.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     chunk_overlap  \u001b[39m=\u001b[39m \u001b[39m2500\u001b[39m,  \u001b[39m# size of  overlap between chunks in order to maintain the context\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://domino-glue01.pg.wwtatc.ai/mnt/process_pdf_text.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell://domino-glue01.pg.wwtatc.ai/mnt/process_pdf_text.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m documents \u001b[39m=\u001b[39m text_splitter\u001b[39m.\u001b[39msplit_documents(loader\u001b[39m.\u001b[39;49mload())\n\u001b[1;32m     <a href='vscode-notebook-cell://domino-glue01.pg.wwtatc.ai/mnt/process_pdf_text.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThere are \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(documents)\u001b[39m}\u001b[39;00m\u001b[39m pages in the document\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/mnt/.venv/lib/python3.9/site-packages/langchain_core/document_loaders/base.py:32\u001b[0m, in \u001b[0;36mBaseLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mload\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mlist\u001b[39m[Document]:\n\u001b[1;32m     31\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load data into Document objects.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlazy_load())\n",
      "File \u001b[0;32m/mnt/.venv/lib/python3.9/site-packages/langchain_community/document_loaders/pdf.py:305\u001b[0m, in \u001b[0;36mPyPDFLoader.lazy_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    304\u001b[0m     blob \u001b[39m=\u001b[39m Blob\u001b[39m.\u001b[39mfrom_path(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfile_path)\n\u001b[0;32m--> 305\u001b[0m \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparser\u001b[39m.\u001b[39mlazy_parse(blob)\n",
      "File \u001b[0;32m/mnt/.venv/lib/python3.9/site-packages/langchain_community/document_loaders/parsers/pdf.py:384\u001b[0m, in \u001b[0;36mPyPDFParser.lazy_parse\u001b[0;34m(self, blob)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[39mreturn\u001b[39;00m page\u001b[39m.\u001b[39mextract_text(\n\u001b[1;32m    379\u001b[0m             extraction_mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mextraction_mode,\n\u001b[1;32m    380\u001b[0m             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mextraction_kwargs,\n\u001b[1;32m    381\u001b[0m         )\n\u001b[1;32m    383\u001b[0m \u001b[39mwith\u001b[39;00m blob\u001b[39m.\u001b[39mas_bytes_io() \u001b[39mas\u001b[39;00m pdf_file_obj:\n\u001b[0;32m--> 384\u001b[0m     pdf_reader \u001b[39m=\u001b[39m pypdf\u001b[39m.\u001b[39;49mPdfReader(pdf_file_obj, password\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpassword)\n\u001b[1;32m    386\u001b[0m     doc_metadata \u001b[39m=\u001b[39m _purge_metadata(\n\u001b[1;32m    387\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39mproducer\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mPyPDF\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcreator\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mPyPDF\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcreationdate\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m    388\u001b[0m         \u001b[39m|\u001b[39m cast(\u001b[39mdict\u001b[39m, pdf_reader\u001b[39m.\u001b[39mmetadata \u001b[39mor\u001b[39;00m {})\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    392\u001b[0m         }\n\u001b[1;32m    393\u001b[0m     )\n\u001b[1;32m    394\u001b[0m     single_texts \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m/mnt/.venv/lib/python3.9/site-packages/pypdf/_reader.py:136\u001b[0m, in \u001b[0;36mPdfReader.__init__\u001b[0;34m(self, stream, strict, password)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_page_id2num: Optional[Dict[Any, Any]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validated_root: Optional[DictionaryObject] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize_stream(stream)\n\u001b[1;32m    137\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_known_objects: Set[Tuple[\u001b[39mint\u001b[39m, \u001b[39mint\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[1;32m    139\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_override_encryption \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/.venv/lib/python3.9/site-packages/pypdf/_reader.py:158\u001b[0m, in \u001b[0;36mPdfReader._initialize_stream\u001b[0;34m(self, stream)\u001b[0m\n\u001b[1;32m    156\u001b[0m         stream \u001b[39m=\u001b[39m BytesIO(fh\u001b[39m.\u001b[39mread())\n\u001b[1;32m    157\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stream_opened \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(stream)\n\u001b[1;32m    159\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream \u001b[39m=\u001b[39m stream\n",
      "File \u001b[0;32m/mnt/.venv/lib/python3.9/site-packages/pypdf/_reader.py:597\u001b[0m, in \u001b[0;36mPdfReader.read\u001b[0;34m(self, stream)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    590\u001b[0m \u001b[39mRead and process the PDF stream, extracting necessary data.\u001b[39;00m\n\u001b[1;32m    591\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    594\u001b[0m \n\u001b[1;32m    595\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    596\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_basic_validation(stream)\n\u001b[0;32m--> 597\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_find_eof_marker(stream)\n\u001b[1;32m    598\u001b[0m startxref \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_find_startxref_pos(stream)\n\u001b[1;32m    599\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_startxref \u001b[39m=\u001b[39m startxref\n",
      "File \u001b[0;32m/mnt/.venv/lib/python3.9/site-packages/pypdf/_reader.py:703\u001b[0m, in \u001b[0;36mPdfReader._find_eof_marker\u001b[0;34m(self, stream)\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[39mraise\u001b[39;00m PdfReadError(\u001b[39m\"\u001b[39m\u001b[39mEOF marker not found\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    702\u001b[0m     logger_warning(\u001b[39m\"\u001b[39m\u001b[39mEOF marker not found\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m__name__\u001b[39m)\n\u001b[0;32m--> 703\u001b[0m line \u001b[39m=\u001b[39m read_previous_line(stream)\n",
      "File \u001b[0;32m/mnt/.venv/lib/python3.9/site-packages/pypdf/_utils.py:294\u001b[0m, in \u001b[0;36mread_previous_line\u001b[0;34m(stream)\u001b[0m\n\u001b[1;32m    292\u001b[0m found_crlf \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[39mif\u001b[39;00m stream\u001b[39m.\u001b[39mtell() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 294\u001b[0m     \u001b[39mraise\u001b[39;00m PdfStreamError(STREAM_TRUNCATED_PREMATURELY)\n\u001b[1;32m    295\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    296\u001b[0m     to_read \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(DEFAULT_BUFFER_SIZE, stream\u001b[39m.\u001b[39mtell())\n",
      "\u001b[0;31mPdfStreamError\u001b[0m: Stream has ended unexpectedly"
     ]
    }
   ],
   "source": [
    "fpath = '/domino/datasets/local/Gartner_Article_Chat'\n",
    "files = [os.path.join(fpath, f) for f in os.listdir(fpath) if os.path.isfile(os.path.join(fpath, f))]\n",
    "\n",
    "loader = PyPDFLoader(files[0])\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 5000,  # size of each chunk created\n",
    "    chunk_overlap  = 2500,  # size of  overlap between chunks in order to maintain the context\n",
    ")\n",
    "documents = text_splitter.split_documents(loader.load())\n",
    "print(f\"There are {len(documents)} pages in the document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gartner, Inc. | G00812459 Page 5 of 8\n",
      "Overview\n",
      "Top Business Priorities for Financial Services Leaders in Banking and\n",
      "Investment Services\n",
      "Modernizing business-critical systems and capabilities is a top priority for 55% of\n",
      "ﬁnancial services leaders in banking and investment services, according to the 2024\n",
      "Gartner Financial Services Business Priority Tracker Survey, 3Q. Other top priorities for the\n",
      "quarter include improving operational efﬁciency (42%), enhancing data and analytics\n",
      "capabilities (32%), minimizing operational risk (32%) and investing in emerging\n",
      "technological capabilities (30%). Conﬁdence in executing against these priorities is\n",
      "generally high, ranging from 55% to 59%.\n",
      "This research note is restricted to the personal use of wesley.palmer@wwt.com.\n"
     ]
    }
   ],
   "source": [
    "# Pick a sample page\n",
    "print(documents[4].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parser.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "from tqdm import tqdm\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from typing import List, Dict\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class DocumentChunk:\n",
    "    content: str\n",
    "    metadata: Dict[str, str]\n",
    "\n",
    "class PDFIngestor:\n",
    "    def __init__(self, data_dir: str, chunk_size: int = 1200, chunk_overlap: int = 300):\n",
    "        self.data_dir = data_dir\n",
    "        self.chunker = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \".\", \" \"]\n",
    "        )\n",
    "\n",
    "    def _load_pdf(self, path: str) -> List[str]:\n",
    "        \"\"\"Extract raw text from each page of the PDF.\"\"\"\n",
    "        doc = fitz.open(path)\n",
    "        pages = [page.get_text(\"text\") for page in doc]\n",
    "        return pages\n",
    "\n",
    "    def _chunk_text(self, text: str, metadata: Dict[str, str]) -> List[DocumentChunk]:\n",
    "        \"\"\"Split long text into overlapping semantic chunks.\"\"\"\n",
    "        chunks = self.chunker.split_text(text)\n",
    "        return [DocumentChunk(content=c, metadata=metadata) for c in chunks]\n",
    "\n",
    "    def ingest(self) -> List[DocumentChunk]:\n",
    "        \"\"\"Main ingestion loop for all PDFs in the data directory.\"\"\"\n",
    "        all_chunks = []\n",
    "        pdf_files = [f for f in os.listdir(self.data_dir) if f.lower().endswith(\".pdf\")]\n",
    "\n",
    "        for pdf in tqdm(pdf_files, desc=\"Processing PDFs\"):\n",
    "            pdf_path = os.path.join(self.data_dir, pdf)\n",
    "            \n",
    "            if check_file_in_pinecone(pdf):\n",
    "                print(f\"Skipping '{pdf}' — already in Pinecone.\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                pages = self._load_pdf(pdf_path)\n",
    "                full_text = \"\\n\\n\".join(pages)\n",
    "                metadata = {\n",
    "                    \"source\": pdf,\n",
    "                    \"page_count\": str(len(pages))\n",
    "                }\n",
    "                chunks = self._chunk_text(full_text, metadata)\n",
    "                all_chunks.extend(chunks)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process {pdf}: {e}\")\n",
    "\n",
    "        return all_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs: 100%|██████████| 2/2 [00:00<00:00, 22.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Chunk ---\n",
      "Gartner, Inc. | G00812459\n",
      "Page 6 of 8\n",
      "Looking ahead 12 months (through 3Q25), we see some shifts across all ﬁve priority and\n",
      "conﬁdence levels. Investment in emerging technological capabilities is projected to\n",
      "become the No. 1 priority, increasing 18 points from 30% to 48%. For several quarters\n",
      "since early 2023, executives have consistently indicated that investing in emerging\n",
      "technology will be their top priority in 12 months. However, data collected from the\n",
      "business priority tracker survey shows that investment in emerging technology has yet to\n",
      "become the No. 1 priority. Organizations seeking to transform their technology must make\n",
      "a concerted effort to align their future priorities and their actions. For more details on how\n",
      "to manage this shift see Ignition Guide to Technology Implementation Change\n",
      "Management. Three out of the ﬁve priorities are expected to decrease in prioritization,\n",
      "showing less differentiation in the signiﬁcance of the priorities. For all ﬁve initiatives,\n",
      "leaders’ conﬁdence in execution is generally projected to increase.\n",
      "Banks Are Focusing on Modernizing and Transforming the Wrong Aspects\n",
      "of Digital Banking Platforms...\n",
      "Metadata: {'source': 'Banking and Investment Services Business Priority Tracker - 812459 - 2025.pdf', 'page_count': '8'}\n",
      "\n",
      "--- Chunk ---\n",
      "showing less differentiation in the signiﬁcance of the priorities. For all ﬁve initiatives,\n",
      "leaders’ conﬁdence in execution is generally projected to increase.\n",
      "Banks Are Focusing on Modernizing and Transforming the Wrong Aspects\n",
      "of Digital Banking Platforms\n",
      "The survey also asked ﬁnancial services leaders in banking and investment services\n",
      "about digital banking platforms. Over the next two years (2025-2026), leaders expect\n",
      "moderate increases in investments associated with modernizing, optimizing and\n",
      "transforming digital banking channels or platforms (DBPs).\n",
      "Improving customer experience is the most-cited reason for organizations to increase\n",
      "investments in DBPs. Based on inquiry with Gartner analysts, customer experience\n",
      "improvements often focus on improving traditional channels. This approach is too narrow\n",
      "and will not likely drive signiﬁcant customer value over the long term, as competitors will\n",
      "invest to maintain competitive parity. Instead, CIOs should pivot their approach to end-to-\n",
      "end digital banking platforms that enable banks to leverage a broader set of transaction\n",
      "types in addition to new products and engagement models that allow for greater...\n",
      "Metadata: {'source': 'Banking and Investment Services Business Priority Tracker - 812459 - 2025.pdf', 'page_count': '8'}\n",
      "\n",
      "--- Chunk ---\n",
      "invest to maintain competitive parity. Instead, CIOs should pivot their approach to end-to-\n",
      "end digital banking platforms that enable banks to leverage a broader set of transaction\n",
      "types in addition to new products and engagement models that allow for greater\n",
      "efﬁciency. This approach to DBPs can create new longer-term advantages around revenue\n",
      "opportunities, reduce operating costs and enable banking transformation that goes\n",
      "beyond just delivery channel transformation. Only 20% of leaders indicate they are\n",
      "thinking about how to create new value using DBPs. For more information on how CIOs\n",
      "can design and operationalize digital banking platforms see Key Building Blocks for\n",
      "Digital Banking Platform’s Success.\n",
      "The survey also asked leaders about where the team leading DBP development ﬁts within\n",
      "their organizational structure. Since 2021, four common organizing models have\n",
      "emerged. These four models are:\n",
      "The digital banking platform team reports into IT.\n",
      "■\n",
      "This research note is restricted to the personal use of wesley.palmer@wwt.com....\n",
      "Metadata: {'source': 'Banking and Investment Services Business Priority Tracker - 812459 - 2025.pdf', 'page_count': '8'}\n",
      "\n",
      "--- Chunk ---\n",
      "Gartner, Inc. | G00812459\n",
      "Page 7 of 8\n",
      "Of note, line of business (LOB) involvement has almost doubled, with the DPB team\n",
      "reporting into the business unit moving from 13% in 2021 to 25% today. This ﬁnding\n",
      "indicates a shift from IT to business-led IT steering the management and development of\n",
      "DBPs with a focus on achieving speciﬁc LOB outcomes.\n",
      "With these planned changes to DBPs, banks are expecting increases across several key\n",
      "business outcomes. Most commonly, leaders expect better customer experiences (74%),\n",
      "followed by the acquisition of new customers (46%), an increase in the percentage of\n",
      "revenue from digital channels (45%) and improved efﬁciency and cost optimization for\n",
      "current operations (42%).\n",
      "Evidence\n",
      "2024 Gartner Financial Services Business Priority Tracker Survey, 3Q. The main objective\n",
      "of this survey was to understand the most pressing priorities of the ﬁnancial services\n",
      "business and technology leaders in the short term. This survey also aimed to get\n",
      "executive perspectives on key topic areas such as goals for 2025, digital banking\n",
      "platforms and generative AI. This survey was conducted online from 22 August through...\n",
      "Metadata: {'source': 'Banking and Investment Services Business Priority Tracker - 812459 - 2025.pdf', 'page_count': '8'}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fpath = '/domino/datasets/local/Gartner_Article_Chat'\n",
    "ingestor = PDFIngestor(data_dir=fpath)\n",
    "chunks = ingestor.ingest()\n",
    "\n",
    "# Example: print first 2 chunks\n",
    "for c in chunks[2:6]:\n",
    "    print(f\"--- Chunk ---\\n{c.content}...\\nMetadata: {c.metadata}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vector_store.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'DocumentChunk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/process_pdf_text.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://domino-glue01.pg.wwtatc.ai/mnt/process_pdf_text.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m     response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39membeddings\u001b[39m.\u001b[39mcreate(\n\u001b[1;32m     <a href='vscode-notebook-cell://domino-glue01.pg.wwtatc.ai/mnt/process_pdf_text.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m         \u001b[39minput\u001b[39m\u001b[39m=\u001b[39m[text],\n\u001b[1;32m     <a href='vscode-notebook-cell://domino-glue01.pg.wwtatc.ai/mnt/process_pdf_text.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m         model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtext-embedding-3-small\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://domino-glue01.pg.wwtatc.ai/mnt/process_pdf_text.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m         dimensions\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://domino-glue01.pg.wwtatc.ai/mnt/process_pdf_text.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell://domino-glue01.pg.wwtatc.ai/mnt/process_pdf_text.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mdata[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39membedding\n\u001b[0;32m---> <a href='vscode-notebook-cell://domino-glue01.pg.wwtatc.ai/mnt/process_pdf_text.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mupsert_chunks_to_pinecone\u001b[39m(chunks: List[DocumentChunk]):\n\u001b[1;32m     <a href='vscode-notebook-cell://domino-glue01.pg.wwtatc.ai/mnt/process_pdf_text.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Convert chunks to embeddings and upsert into pc\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://domino-glue01.pg.wwtatc.ai/mnt/process_pdf_text.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m     vectors \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DocumentChunk' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pinecone import Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from typing import List\n",
    "from uuid import uuid4\n",
    "\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "#pinecone_env = os.getenv(\"PINECONE_ENVIRONMENT\")\n",
    "pinecone_index_name = os.getenv(\"PINECONE_INDEX_NAME\")\n",
    "embedding_dimension = 512 \n",
    "\n",
    "# Initialize Pinecone\n",
    "pc = Pinecone(api_key = pinecone_api_key)\n",
    "\n",
    "client = OpenAI(api_key = openai_key)\n",
    "\n",
    "# Create index if needed\n",
    "if not pc.has_index(pinecone_index_name):\n",
    "    print(f\"Creating Pinecone index '{pinecone_index_name}' with dimension {embedding_dimension}...\")\n",
    "    pc.create_index(\n",
    "        name=pinecone_index_name,\n",
    "        dimension=embedding_dimension,\n",
    "        metric = \"cosine\",\n",
    "        spec = ServerlessSpec(cloud='aws', region='us-east-1')\n",
    "    )\n",
    "\n",
    "# Connect to the index\n",
    "index = pc.Index(pinecone_index_name)\n",
    "\n",
    "def get_embedding(text: str) -> List[float]:\n",
    "    response = client.embeddings.create(\n",
    "        input=[text],\n",
    "        model=\"text-embedding-3-small\",\n",
    "        dimensions=512\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "def upsert_chunks_to_pinecone(chunks: List[DocumentChunk]):\n",
    "    \"\"\"Convert chunks to embeddings and upsert into pc\"\"\"\n",
    "    vectors = []\n",
    "    for chunk in chunks:\n",
    "        try:\n",
    "            emb = get_embedding(chunk.content)\n",
    "            vector = {\n",
    "                \"id\": str(uuid4()),\n",
    "                \"values\": emb,\n",
    "                \"metadata\": {\n",
    "                    \"text\": chunk.content,  # Optional truncation\n",
    "                    **chunk.metadata\n",
    "                }\n",
    "            }\n",
    "            vectors.append(vector)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to embed chunk: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Upsert in batches\n",
    "    batch_size = 100\n",
    "    for i in range(0, len(vectors), batch_size):\n",
    "        batch = vectors[i:i + batch_size]\n",
    "        index.upsert(vectors=batch)\n",
    "        print(f\"Upserted {i + len(batch)} / {len(vectors)} vectors\")\n",
    "\n",
    "def check_file_in_pinecone(source_filename: str) -> bool:\n",
    "    dummy_vector = [0.0] * 512  # Match embedding dim\n",
    "    try:\n",
    "        response = index.query(\n",
    "            vector=dummy_vector,\n",
    "            top_k=1,\n",
    "            include_metadata=True,\n",
    "            filter={\"source\": source_filename}\n",
    "        )\n",
    "        matches = response.get(\"matches\", [])\n",
    "        return len(matches) > 0\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to check for existing file: {e}\")\n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserted 92 / 92 vectors\n"
     ]
    }
   ],
   "source": [
    "upsert_chunks_to_pinecone(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
